name: Preprocess data
description: Cleans, scales and splits the dataset.
inputs:
- {name: input_csv, type: String}
- {name: output_dir, type: String}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def preprocess_data(input_csv, output_dir):
          """
          Cleans, scales and splits the dataset.
          Saves: X_train.csv, X_test.csv, y_train.csv, y_test.csv
          """
          df = pd.read_csv(input_csv)

          X = df.drop("TARGET", axis=1)
          y = df["TARGET"]

          scaler = StandardScaler()
          X_scaled = scaler.fit_transform(X)

          X_train, X_test, y_train, y_test = train_test_split(
              X_scaled, y, test_size=0.2, random_state=42
          )

          if not os.path.exists(output_dir):
              os.makedirs(output_dir)

          pd.DataFrame(X_train).to_csv(f"{output_dir}/X_train.csv", index=False)
          pd.DataFrame(X_test).to_csv(f"{output_dir}/X_test.csv", index=False)
          y_train.to_csv(f"{output_dir}/y_train.csv", index=False)
          y_test.to_csv(f"{output_dir}/y_test.csv", index=False)

          print("Preprocessing complete. Files saved to:", output_dir)

      import argparse
      _parser = argparse.ArgumentParser(prog='Preprocess data', description='Cleans, scales and splits the dataset.')
      _parser.add_argument("--input-csv", dest="input_csv", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--output-dir", dest="output_dir", type=str, required=True, default=argparse.SUPPRESS)
      _parsed_args = vars(_parser.parse_args())

      _outputs = preprocess_data(**_parsed_args)
    args:
    - --input-csv
    - {inputValue: input_csv}
    - --output-dir
    - {inputValue: output_dir}
